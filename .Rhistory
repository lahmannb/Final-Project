treefit3 <- tree(log(MedianHouseValue) ~., data=x)
plot(x$Longitude,x$Latitude,col=grey(10:2/11)[cut.prices],pch=20,
xlab="Longitude",ylab="Latitude")
cut.predictions = cut(predict(treefit3),log(price.deciles),include.lowest=TRUE)
plot(x$Longitude,x$Latitude,col=grey(10:2/11)[cut.predictions],pch=20,
xlab="Longitude",ylab="Latitude")
summary(treefit3)
treefit2 <- tree(log(MedianHouseValue) ~ Longitude + Latitude, data=x, mindev=0.001)
plot(treefit2)
text(treefit, cex=.75)
treefit2 <- tree(log(MedianHouseValue) ~ Longitude + Latitude, data=x, mindev=0.001)
plot(treefit2)
text(treefit2, cex=.75)
treefit3 <- tree(log(MedianHouseValue) ~., data=x)
plot(treefit3)
text(treefit3, cex=.75)
#Problem 2
wine = read.csv("http://www.nd.edu/~mclark19/learn/data/goodwine.csv")
summary(wine)
library(caret)
library(lattice)
library(ggplot2)
library(nnet)
library(randomForest)
library(kernlab)
#parallel processing
library(foreach)
library(doSNOW)
registerDoSNOW(makeCluster(3, type = "SOCK"))
#Correlation Matrix
library(corrplot)
corrplot(cor(wine[, -c(13, 15)]), method = "number", tl.cex = 0.5)
#Indices in Training Set
set.seed(1234) #so that the indices will be the same when re-run
trainIndices = createDataPartition(wine$good, p = 0.8, list = F)
wanted = !colnames(wine) %in% c("free.sulfur.dioxide", "density", "quality",
"color", "white")
wine_train = wine[trainIndices, wanted] #remove quality and color, as well as density and others
wine_test = wine[-trainIndices, wanted]
#initial Peek at wine trainplot and feature plot
wine_trainplot = predict(preProcess(wine_train[,-10], method="range"), wine_train[,-10])
featurePlot(wine_trainplot, wine_train$good, "box")
#set values of k
library(e1071)
set.seed(1234)
cv_opts = trainControl(method="cv", number=10)
knn_opts = data.frame(.k=c(seq(3, 11, 2), 25, 51, 101)) #odd to avoid ties
results_knn = train(good~., data=wine_train, method="knn",
preProcess="range", trControl=cv_opts,
tuneGrid = knn_opts)
results_knn
#testing the model with k=3
preds_knn = predict(results_knn, wine_test[,-10])
confusionMatrix(preds_knn, wine_test[,10], positive='Good')
load('Cotropia_Kesan_Schwartz_2010_PatentHolderandLitigationDataset_5.28.14')
load("/Users/lahmannb/Downloads/applications20012010_bib.RData")
data<-/Users/lahmannb/Downloads/applications20012010_bib.RData
data
dataset<-load("/Users/lahmannb/Downloads/applications20012010_bib.RData")
head(dataset)
dataset
View(x)
View(x)
View(x)
View(x)
View(x)
View(x)
View(x)
library(foreign)
cars = read.delim("http://www.stat.berkeley.edu/classes/~s133/data/cars.tab", stringsAsFactors=FALSE)
cars = read.delim("http://www.stat.berkeley.edu/~s133/data/cars.tab", stringsAsFactors=FALSE)
head(cars)
cars.use = cars[,-c(1,2)]
medians = apply(cars.use,2,median)
mads = apply(cars.use,2,mad)
cars.use = scale(cars.use,center=medians,scale=mads)
cars.dist = dist(cars.use)
(cars.dist = dist(cars.use))
car.dist
cars.dist = dist(cars.use)
car.dist
cars.dist
cars.hclust = hclust(cars.dist)
plot(cars.hclust,labels=cars$Car,main='Default from hclust')
groups.3 = cutree(cars.hclust,3)
table(groups.3)
counts = sapply(2:6,function(ncl)table(cutree(cars.hclust,ncl)))
names(counts) = 2:6
counts
cars$Car[groups.3 == 1]
sapply(unique(groups.3),function(g)cars$Car[groups.3 == g])
groups.4 = cutree(cars.hclust,4)
sapply(unique(groups.4),function(g)cars$Car[groups.4 == g])
table(groups.3,cars$Country)
aggregate(cars.use,list(groups.3),median)
aggregate(cars[,-c(1,2)],list(groups.3),median)
a3 = aggregate(cars[,-c(1,2)],list(groups.3),median)
data.frame(Cluster=a3[,1],Freq=as.vector(table(groups.3)),a3[,-1])
a4 = aggregate(cars[,-c(1,2)],list(groups.4),median)
data.frame(Cluster=a4[,1],Freq=as.vector(table(groups.4)),a4[,-1])
library(cluster)
cars.pam = pam(cars.dist,3)
names(cars.pam)
table(groups.3,cars.pam$clustering)
cars$Car[groups.3 != cars.pam$clustering]
ars$Car[cars.pam$id.med]
cars$Car[cars.pam$id.med]
plot(cars.pam)
plot(silhouette(cutree(cars.hclust,4),cars.dist))
head(iris)
#part 1
library(foreign)
cars = read.delim("http://www.stat.berkeley.edu/~s133/data/cars.tab", stringsAsFactors=FALSE)
head(cars)
#Using Apply Function
cars.use = cars[,-c(1,2)]
medians = apply(cars.use,2,median)
mads = apply(cars.use,2,mad)
cars.use = scale(cars.use,center=medians,scale=mads)
#dist function
(cars.dist = dist(cars.use))
#hclust
cars.hclust = hclust(cars.dist)
#plot
plot(cars.hclust,labels=cars$Car,main='Default from hclust')
#group
#Problem 3
#part 1
library(foreign)
cars = read.delim("http://www.stat.berkeley.edu/~s133/data/cars.tab", stringsAsFactors=FALSE)
head(cars)
#Using Apply Function
cars.use = cars[,-c(1,2)]
medians = apply(cars.use,2,median)
mads = apply(cars.use,2,mad)
cars.use = scale(cars.use,center=medians,scale=mads)
#dist function
(cars.dist = dist(cars.use))
#hclust
cars.hclust = hclust(cars.dist)
#plot
plot(cars.hclust,labels=cars$Car,main='Default from hclust')
#group
groups.3 = cutree(cars.hclust,3)
table(groups.3)
#cut tree and table
counts = sapply(2:6,function(ncl)table(cutree(cars.hclust,ncl)))
names(counts) = 2:6
counts
#Which cars are in which groups?
cars$Car[groups.3 == 1]
#or us sapply
sapply(unique(groups.3),function(g)cars$Car[groups.3 == g])
# 4 cluster
groups.4 = cutree(cars.hclust,4)
sapply(unique(groups.4),function(g)cars$Car[groups.4 == g])
#Cross tabulation
table(groups.3,cars$Country)
aggregate(cars.use,list(groups.3),median)
aggregate(cars[,-c(1,2)],list(groups.3),median)
#a3
a3 = aggregate(cars[,-c(1,2)],list(groups.3),median)
data.frame(Cluster=a3[,1],Freq=as.vector(table(groups.3)),a3[,-1])
a4 = aggregate(cars[,-c(1,2)],list(groups.4),median)
data.frame(Cluster=a4[,1],Freq=as.vector(table(groups.4)),a4[,-1])
#Part 2 K-means clustering
wssplot <- function(data, nc=15, seed=1234){
wss <- (nrow(data)-1)*sum(apply(data,2,var))
for (i in 2:nc){
set.seed(seed)
wss[i] <- sum(kmeans(data, centers=i)$withinss)}
plot(1:nc, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")
}
data(wine, package="rattle")
head(wine)
df <- scale(wine[-1]) #1 Standardize data
wssplot(df)           #2determine number of clusters
library(NbClust)
set.seed(1234)
nc <- NbClust(df, min.nc=2, max.nc=15, method="kmeans")
table(nc$Best.n[1,])
barplot(table(nc$Best.n[1,]),
xlab="Number of Clusters", ylab="Number of Criteria",
main="Number of Clusters Chosen by 26 Criteria")
set.seed(1234)
fit.km <- kmeans(df, 3, nstart=25)                           #3 K means cluster analysis
fit.km$size
fit.km$centers
aggregate(wine[-1], by=list(cluster=fit.km$cluster), mean)
# how did kmeans do?
ct.km <- table(wine$Type, fit.km$cluster)
ct.km
library(flexclust)
randIndex(ct.km)
library(foreign)
titanic3 <- read.csv("http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv")
dim(titanic3)
set.seed(1234)
ind <- sample(2, nrow(titanic3), replace=TRUE, prob=c(0.50, 0.50))
titanic.train <- titanic3[ind==1,]
titanic.test <- titanic3[ind==2,]
#GLM
titanic.survival.train = glm(survived ~ pclass + sex + pclass:sex + age + sibsp,
family = binomial(logit), data = titanic.train)
summary(titanic.survival.train)
#Random Forest
library(randomForest)
titanic.survival.train.rf = randomForest(as.factor(survived) ~ pclass + sex + age + sibsp,
data=titanic.train,ntree=5000,
importance=TRUE, na.action = na.omit)
#input the omit term because some of the ages were omitted in the data
titanic.survival.train.rf
importance(titanic.survival.train.rf)
#Conditional Tree
library(party)
titanic.survival.train.ctree = ctree(as.factor(survived) ~ pclass + sex + age + sibsp, data=titanic.train)
titanic.survival.train.ctree
plot(titanic.survival.train.ctree)
library(foreign)
titanic3 <- read.csv("http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv")
dim(titanic3)
set.seed(1234)
ind <- sample(2, nrow(titanic3), replace=TRUE, prob=c(0.50, 0.50))
titanic.train <- titanic3[ind==1,]
titanic.test <- titanic3[ind==2,]
#GLM
titanic.survival.train = glm(survived ~ pclass + sex + pclass:sex + age + sibsp,
family = binomial(logit), data = titanic.train)
summary(titanic.survival.train)
titanic.survival.train.rf = randomForest(as.factor(survived) ~ pclass + sex + age + sibsp,
data=titanic.train,ntree=5000,
importance=TRUE, na.action = na.omit)
library(randomForest)
titanic.survival.train.rf = randomForest(as.factor(survived) ~ pclass + sex + age + sibsp,
data=titanic.train,ntree=5000,
importance=TRUE, na.action = na.omit)
#input the omit term because some of the ages were omitted in the data
titanic.survival.train.rf
importance(titanic.survival.train.rf)
library(party)
titanic.survival.train.ctree = ctree(as.factor(survived) ~ pclass + sex + age + sibsp, data=titanic.train)
titanic.survival.train.ctree
plot(titanic.survival.train.ctree)
#Get Gapminder Data
gdURL <- "http://www.stat.ubc.ca/~jenny/notOcto/STAT545A/examples/gapminder/data/gapminderDataFiveYear.txt"
gDat <- read.delim(file = gdURL)
str(gDat)
#Data Agreegation
(snippet <- subset(gDat, country == "Canada"))
#Plyr I already had it installed
library(plyr)
(maxLeByCont <- ddply(gDat, ~ continent, summarize, maxLifeExp = max(lifeExp)))
str(maxLeByCont)
levels(maxLeByCont$continent)
#Calculate Min. GDP per Continent
(mingdpPercap <- ddply(gDat, ~continent, summarize, minGDPperCap = min(gdpPercap)))
#Number of Countries
ddply(gDat, ~continent, summarize, nUniqCountries = length(unique(country)))
#Same thing but w/o summarize
ddply(gDat, ~ continent,function(x) return(c(nUniqCountries = length(unique(x$country)))))
# can compute multiple things at once!!!
ddply(gDat, ~ continent, summarize,
minLifeExp = min(lifeExp), maxLifeExp = max(lifeExp),
medGdpPercap = median(gdpPercap))
#PUtting it all together
jCountry <- "France"  # pick, but do not hard wire, an example
(jDat <- subset(gDat, country == jCountry))  # temporary measure!
xyplot(lifeExp ~ year, jDat, type = c("p", "r"))  # always plot the data
help(xyplot)
xyplot(lifeExp ~ year, jDat, type = c("p", "r"))  # always plot the data
install.packages("xyplot")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
xyplot(lifeExp ~ year, jDat, type = c("p", "r"))  # always plot the data
library("lattice", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
xyplot(lifeExp ~ year, jDat, type = c("p", "r"))  # always plot the data
library(lattice)
xyplot(lifeExp ~ year, jDat, type = c("p", "r"))  # always plot the data
jFit <- lm(lifeExp ~ year, jDat)
summary(jFit)
(yearMin <- min(gDat$year))
jFit <- lm(lifeExp ~ I(year - yearMin), jDat)
summary(jFit)
class(jFit)
mode(jFit)
str(jFit) # too ugly to print here but you should look
names(jFit)
jFit$coefficients
coef(jFit)
jFun <- function(x) coef(lm(lifeExp ~ I(year - yearMin), x))
jFun(jDat)  # trying out our new function ... yes still get same numbers
jFun(subset(gDat, country == "Canada"))
jFun(subset(gDat, country == "Uruguay"))
jFun(subset(gDat, country == "India"))
jCoefs <- ddply(gDat, ~country, jFun)
str(jCoefs)
tail(jCoefs)
#This would be the final script
## realistically, you would read the data from a local file
gdURL <- "http://www.stat.ubc.ca/~jenny/notOcto/STAT545A/examples/gapminder/data/gapminderDataFiveYear.txt"
gDat <- read.delim(file = gdURL)
## str(gDat) here when working interactively
yearMin <- min(gDat$year)
jFun <- function(x) {
estCoefs <- coef(lm(lifeExp ~ I(year - yearMin), x))
names(estCoefs) <- c("intercept", "slope")
return(estCoefs)
}
## jFun(subset(gDat, country == 'India')) to see what it does
jCoefs <- ddply(gDat, ~country, jFun)
#xtable package
install.packages("xtable", dependencies = TRUE)
library(xtable)
set.seed(916)
foo <- jCoefs[sample(nrow(jCoefs), size = 15), ]
foo <- xtable(foo)
print(foo, type = "html", include.rownames = FALSE)
#ddply again
jCoefs <- ddply(gDat, ~country, jFun)
jCoefs <- ddply(gDat, ~country + continent, jFun)
str(jCoefs)
tail(jCoefs)
#1952 age table
set.seed(916)
foo <- jCoefs[sample(nrow(jCoefs), size = 15), ]
foo <- arrange(foo, intercept)
## foo <- foo[order(foo$intercept), ] # an uglier non-plyr way
foo <- xtable(foo)
print(foo, type = "html", include.rownames = FALSE)
#Q&A How to pass more than 1 arg. into ddply() Below is what we started with
(yearMin <- min(gDat$year))
jFun <- function(x) {
estCoefs <- coef(lm(lifeExp ~ I(year - yearMin), x))
names(estCoefs) <- c("intercept", "slope")
return(estCoefs)
}
jCoefs <- ddply(gDat, ~country, jFun)
head(jCoefs)
#Answer more than 1 arg.
jFunTwoArgs <- function(x, cvShift = 0) {
estCoefs <- coef(lm(lifeExp ~ I(year - cvShift), x))
names(estCoefs) <- c("intercept", "slope")
return(estCoefs)
}
jCoefsSilly <- ddply(gDat, ~country, jFunTwoArgs)
head(jCoefsSilly)
jCoefsSane <- ddply(gDat, ~country, jFunTwoArgs, cvShift = 1952)
head(jCoefsSane)
jCoefsBest <- ddply(gDat, ~country, jFunTwoArgs, cvShift = min(gDat$year))
head(jCoefsBest)
library("knitr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("markdown", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("rmarkdown", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
#Problem 3
#part 1
library(foreign)
cars = read.delim("http://www.stat.berkeley.edu/~s133/data/cars.tab", stringsAsFactors=FALSE)
head(cars)
#Using Apply Function
cars.use = cars[,-c(1,2)]
medians = apply(cars.use,2,median)
mads = apply(cars.use,2,mad)
cars.use = scale(cars.use,center=medians,scale=mads)
#dist function
(cars.dist = dist(cars.use))
#hclust
cars.hclust = hclust(cars.dist)
#plot
plot(cars.hclust,labels=cars$Car,main='Default from hclust')
#group
groups.3 = cutree(cars.hclust,3)
table(groups.3)
#cut tree and table
counts = sapply(2:6,function(ncl)table(cutree(cars.hclust,ncl)))
names(counts) = 2:6
counts
#Which cars are in which groups?
cars$Car[groups.3 == 1]
#or us sapply
sapply(unique(groups.3),function(g)cars$Car[groups.3 == g])
# 4 cluster
groups.4 = cutree(cars.hclust,4)
sapply(unique(groups.4),function(g)cars$Car[groups.4 == g])
#Cross tabulation
table(groups.3,cars$Country)
aggregate(cars.use,list(groups.3),median)
aggregate(cars[,-c(1,2)],list(groups.3),median)
#a3
a3 = aggregate(cars[,-c(1,2)],list(groups.3),median)
data.frame(Cluster=a3[,1],Freq=as.vector(table(groups.3)),a3[,-1])
a4 = aggregate(cars[,-c(1,2)],list(groups.4),median)
data.frame(Cluster=a4[,1],Freq=as.vector(table(groups.4)),a4[,-1])
#Part 2 K-means clustering
wssplot <- function(data, nc=15, seed=1234){
wss <- (nrow(data)-1)*sum(apply(data,2,var))
for (i in 2:nc){
set.seed(seed)
wss[i] <- sum(kmeans(data, centers=i)$withinss)}
plot(1:nc, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")
}
data(wine, package="rattle")
head(wine)
df <- scale(wine[-1]) #1 Standardize data
wssplot(df)           #2determine number of clusters
library(NbClust)
set.seed(1234)
nc <- NbClust(df, min.nc=2, max.nc=15, method="kmeans")
table(nc$Best.n[1,])
barplot(table(nc$Best.n[1,]),
xlab="Number of Clusters", ylab="Number of Criteria",
main="Number of Clusters Chosen by 26 Criteria")
set.seed(1234)
fit.km <- kmeans(df, 3, nstart=25)                           #3 K means cluster analysis
fit.km$size
fit.km$centers
aggregate(wine[-1], by=list(cluster=fit.km$cluster), mean)
# how did kmeans do?
ct.km <- table(wine$Type, fit.km$cluster)
ct.km
library(flexclust)
randIndex(ct.km)
#Final Project Code
#load packages that might be used
library(gdata)
library(dplyr)
library(ggplot2)
#Set Working Directory for Dataset
setwd("Documents/Legal Analytics/Final Project/")
pat_lit_data <- tbl_df(read.csv("Pat_Lit_Data_CSV.csv"))
View(pat_lit_data)
View(pat_lit_data)
workdata<-pat_lit_data %>%
select(Renewal, Reissuedummy, Continuation, Division, Claims, NumRefs, DJ, PatDef, DCNumPatents, DCDecision) %>% #took out district because the info wasn't useful
na.omit()
pat_lit_data$ReissueOf<-as.numeric(as.character(pat_lit_data$ReissueOf))
tf<-is.na(pat_lit_data$ReissueOf)
pat_lit_data$ReissueOf[tf]<-0
#the following uses DplyR to create a new column for a reissue dummy variable
pat_lit_data<-pat_lit_data  %>%
mutate(Reissuedummy=as.numeric(ReissueOf>1))
pat_lit_data$NumRefs<-as.numeric(as.character(pat_lit_data$NumRefs))
workdata<-pat_lit_data %>%
select(Renewal, Reissuedummy, Continuation, Division, Claims, NumRefs, DJ, PatDef, DCNumPatents, DCDecision) %>% #took out district because the info wasn't useful
na.omit()
library(randomForest)
dim(workdata)
class(workdata$Claims)
set.seed(1234)
ind<-sample(2,nrow(workdata),replace=TRUE,prob=c(0.7,0.3))
workdata.train <- workdata[ind==1,]
workdata.test <- workdata[ind==2,]
# Random Forest
forest_train=randomForest(DCDecision ~ ., data = workdata.train)
print(forest_train)
getTree(workdata.rf, 1, labelVar=TRUE)
getTree(forest_train, 1, labelVar=TRUE)
set.seed(4543)
data(workdata)
dim(workdata)
set.seed(4543)
data(workdata)
workdata.rf <- randomForest(DCDecision ~ ., data=workdata, ntree=1000,
keep.forest=FALSE, importance=TRUE)
importance(workdata.rf)
importance(workdata.rf, type=1)
importance(forest_train)
table(testforest, workdata.test$DCDecision) #confusion matrix for test set
testforest = predict(forest_train, newdata=workdata.test)
table(testforest, workdata.test$DCDecision) #confusion matrix for test set
library(foreign)
titanic3 <- read.csv("http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv")
dim(titanic3)
set.seed(1234)
ind <- sample(2, nrow(titanic3), replace=TRUE, prob=c(0.50, 0.50))
titanic.train <- titanic3[ind==1,]
titanic.test <- titanic3[ind==2,]
#GLM
titanic.survival.train = glm(survived ~ pclass + sex + pclass:sex + age + sibsp,
family = binomial(logit), data = titanic.train)
summary(titanic.survival.train)
#Random Forest
library(randomForest)
titanic.survival.train.rf = randomForest(as.factor(survived) ~ pclass + sex + age + sibsp,
data=titanic.train,ntree=5000,
importance=TRUE, na.action = na.omit)
#input the omit term because some of the ages were omitted in the data
titanic.survival.train.rf
importance(titanic.survival.train.rf)
#Conditional Tree
library(party)
titanic.survival.train.ctree = ctree(as.factor(survived) ~ pclass + sex + age + sibsp, data=titanic.train)
titanic.survival.train.ctree
plot(titanic.survival.train.ctree)
set.seed(1234)
ind<-sample(2,nrow(workdata),replace=TRUE,prob=c(0.7,0.3))
workdata.train <- workdata[ind==1,]
workdata.test <- workdata[ind==2,]
forest_train=randomForest(DCDecision ~ ., data = workdata.train, ntree=5000, importance= TRUE)
print(forest_train)
importance(forest_train)
testforest = predict(forest_train, newdata=workdata.test)
table(testforest, workdata.test$DCDecision) #confusion matrix for test set
testforest = predict(titanic.survival.train.rf, newdata=titanic.test)
table(testforest, titanic.test$survival)
table(testforest, titanic.test$survived)
varImpPlot(forest_train, sort=TRUE, n.var=min(30, nrow(forest_train$DCDecision))
varImpPlot(forest_train, sort=TRUE, n.var=min(30, nrow(forest_train$DCDecision)))
#Test my Random Forest
varImpPlot(forest_train, sort=TRUE, n.var=min(30, nrow(forest_train$DCDecision)))
varImpPlot(forest_train, sort=TRUE, n.var=min(30, nrow(forest_train$DCDecision)))
varImpPlot(forest_train, sort=TRUE, n.var=min(30, nrow(forest_train$DCDecision)),
scale=TRUE)
varImpPlot(forest_train)
